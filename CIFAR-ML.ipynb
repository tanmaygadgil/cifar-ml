{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f3158c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-1.1.5-cp36-cp36m-win_amd64.whl (8.7 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\tanma\\anaconda3\\envs\\pacman\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\tanma\\anaconda3\\envs\\pacman\\lib\\site-packages (from pandas) (1.19.2)\n",
      "Collecting pytz>=2017.2\n",
      "  Downloading pytz-2022.1-py2.py3-none-any.whl (503 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tanma\\anaconda3\\envs\\pacman\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, pandas\n",
      "Successfully installed pandas-1.1.5 pytz-2022.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mglearn 0.1.6 requires cycler, which is not installed.\n",
      "mglearn 0.1.6 requires matplotlib, which is not installed.\n",
      "mglearn 0.1.6 requires scikit-learn, which is not installed.\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b70fe211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106a6045",
   "metadata": {},
   "source": [
    "\n",
    "## Metrics\n",
    "\n",
    "\n",
    "1. Accuracy\n",
    "2. Confusion Matrix\n",
    "\n",
    "Classification report\n",
    "\n",
    "3. Precision (macro, micro, ave)\n",
    "4. Recall (macro, micro, ave)\n",
    "5. F1 (macro, micro, ave)\n",
    "6. ROC Curves\n",
    "6. Log time\n",
    "\n",
    "\n",
    "\n",
    "[Classification Metrics](https://towardsdatascience.com/comprehensive-guide-on-multiclass-classification-metrics-af94cfb83fbd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9d1d74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a94f024a",
   "metadata": {},
   "source": [
    "## Method 1 - Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d6b49d",
   "metadata": {},
   "source": [
    "Loading the dataset and building train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35d3201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import numpy as np\n",
    "\n",
    "#################### Your Code ####################\n",
    "ROOT_PATH='/Users/smoothoperator/Documents/SML/Final Project/'  # Modify this line with the path to the folder where folder \"cifar-10-batches-py\" locate\n",
    "###################################################\n",
    "\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67916f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define batches\n",
    "batch1 = unpickle(ROOT_PATH+\"cifar-10-batches-py/data_batch_1\")\n",
    "batch2 = unpickle(ROOT_PATH+\"cifar-10-batches-py/data_batch_2\")\n",
    "batch3 = unpickle(ROOT_PATH+\"cifar-10-batches-py/data_batch_3\")\n",
    "batch4 = unpickle(ROOT_PATH+\"cifar-10-batches-py/data_batch_4\")\n",
    "batch5 = unpickle(ROOT_PATH+\"cifar-10-batches-py/data_batch_5\")\n",
    "test_batch = unpickle(ROOT_PATH+\"cifar-10-batches-py/test_batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f04ecfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data0(btch):\n",
    "    labels = btch[b'labels']\n",
    "    imgs = btch[b'data'].reshape((-1, 32, 32, 3))\n",
    "    \n",
    "    res = []\n",
    "    for ii in range(imgs.shape[0]):\n",
    "        img = imgs[ii].copy()\n",
    "        img = np.fliplr(np.rot90(np.transpose(img.flatten().reshape(3,32,32)), k=-1))\n",
    "        res.append(img)\n",
    "    imgs = np.stack(res)\n",
    "    return labels, imgs\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    x_train_l = []\n",
    "    y_train_l = []\n",
    "    for ibatch in [batch1, batch2, batch3, batch4, batch5]:\n",
    "        labels, imgs = load_data0(ibatch)\n",
    "        x_train_l.append(imgs)\n",
    "        y_train_l.extend(labels)\n",
    "    x_train = np.vstack(x_train_l)\n",
    "    y_train = np.vstack(y_train_l)\n",
    "    \n",
    "    x_test_l = []\n",
    "    y_test_l = []\n",
    "    labels, imgs = load_data0(test_batch)\n",
    "    x_test_l.append(imgs)\n",
    "    y_test_l.extend(labels)\n",
    "    x_test = np.vstack(x_test_l)\n",
    "    y_test = np.vstack(y_test_l)\n",
    "    return (x_train, y_train), (x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15a1f2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "del batch1, batch2, batch3, batch4, batch5, test_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a80d511",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#################### Your Code ####################\n",
    "\n",
    "\n",
    "\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b67299",
   "metadata": {},
   "source": [
    "## Method 2 - Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a905fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93f4497b",
   "metadata": {},
   "source": [
    "## Method 3 - Deep Neural Network without Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31017536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71f5eac3",
   "metadata": {},
   "source": [
    "## Method 4 - Deep Neural Network with ConvolutionÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc03feee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
